# -*- coding: utf-8 -*-
"""FixBenerInsyaAllah.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aEXAl8ez_CKwQzd_6sN_eFT-szWoaY8G
"""

#Haris Amaldi
#Dilarang mengcopy code. PLAGIARISME ITU HARAM!!!!

#Membuka file dataset
!unzip datafilm.zip

#Mengimport fungsi-fungsi yang dibutuhkan dan mencari banyaknya data film dan pengguna yang tercatat.
import os
import plotly.express as px
import numpy as np
from datetime import datetime
import pandas as pd
import plotly.graph_objects as go
import seaborn as sns
import re
from sklearn.neighbors import NearestNeighbors
import random
from mlxtend.frequent_patterns import apriori
from mlxtend.frequent_patterns import association_rules

film = pd.read_csv("movies.csv")
rating = pd.read_csv("ratings.csv")

print('Jumlah data film: ', len(film.movieId.unique()))
print('Jumlah data pengguna: ', len(rating.userId.unique()))

#Melihat bentuk data film
film.info()

#Melihat bentuk data rating
rating.info()

# Menggabungkan seluruh movieId pada kategori film dan rating
film_all = np.concatenate((
    film.movieId.unique(),
    rating.movieId.unique()
))
 
# Mengurutkan data dan menghapus data yang sama
film_all = np.sort(np.unique(film_all))
 
print('Jumlah seluruh data film berdasarkan movieID: ', len(film_all))

filmrating = pd.merge(film, rating , on='movieId', how='left')
filmrating

print("Rating yang tersedia:", filmrating.rating.unique())

filmrating.isnull().sum()

filmrating = filmrating.dropna()
filmrating

# Memisahkan tahun rilis film menjadi 1 kolom sendiri
filmrating['tahunrilis'] = filmrating.title.str.extract('.*\((.*)\).*')
filmrating.head()

# Menghapus tahun dari kolom judul
filmrating['title'] = filmrating.title.str.split('(').str[0].str[:-1]
filmrating.head()

#mengubah timestamp menjadi data yang bisa dibaca
def UNIX_to_Readable(df):
    return pd.to_datetime(datetime.fromtimestamp(df).strftime('%Y-%m-%d %H:%M:%S'))


filmrating.timestamp = filmrating.timestamp.apply(UNIX_to_Readable)
filmrating.head()

# Menghapus nilai rating berkoma (Tidak bulat)
filmrating.rating = np.ceil(filmrating.rating)
print("Rating yang tersedia:", filmrating.rating.unique())

#Pengujian penambahan Jumlah rating agar ketahuan apakah ada yang hanya dirating kurang dari 10 pengguna.
filmrating.groupby('movieId').sum()

#Ada yang jumlah ratingnya dibawah rentang 10-50. Harus dihapus terlebih dahulu biar lebih cepat dan efektif.
movieFrequency_greater_10 = filmrating['movieId'].value_counts()[filmrating['movieId'].value_counts() >= 10].index
filmrating = filmrating[filmrating.movieId.isin(movieFrequency_greater_10)]

#Preparasi data
preparasi = filmrating
preparasi.sort_values('movieId')

preparasi = preparasi.drop_duplicates('movieId')
preparasi

Idfilm = preparasi['movieId'].tolist()
Judul = preparasi['title'].tolist()
Genre = preparasi['genres'].tolist()

print(len(Idfilm))
print(len(Judul))
print(len(Genre))

#Membuat dictionary baru
dictbaru = pd.DataFrame({
    'idfilm': Idfilm,
    'Judulfilm': Judul,
    'Genrefilm': Genre
})
dictbaru

"""Ini content based filtering"""

data = dictbaru
data.sample(5)

from sklearn.feature_extraction.text import TfidfVectorizer
 
# Inisialisasi TfidfVectorizer
tf = TfidfVectorizer()
 
# Melakukan perhitungan idf pada data genre film
tf.fit(data['Genrefilm']) 
 
# Mapping array dari fitur index integer ke fitur nama
tf.get_feature_names()

# Melakukan fit lalu ditransformasikan ke bentuk matrix
tfidf_matrix = tf.fit_transform(data['Genrefilm']) 
 
# Melihat ukuran matrix tfidf
tfidf_matrix.shape

# Mengubah vektor tf-idf dalam bentuk matriks dengan fungsi todense()
tfidf_matrix.todense()

# Membuat dataframe untuk melihat tf-idf matrix
# Kolom diisi dengan genre film
# Baris diisi dengan judul film
 
pd.DataFrame(
    tfidf_matrix.todense(), 
    columns=tf.get_feature_names(),
    index=data.Judulfilm
).sample(21, axis=1).sample(10, axis=0)

from sklearn.metrics.pairwise import cosine_similarity
 
# Menghitung cosine similarity pada matrix tf-idf
cosine_sim = cosine_similarity(tfidf_matrix) 
cosine_sim

# Membuat dataframe dari variabel cosine_sim dengan baris dan kolom berupa judul film
cosine_sim_df = pd.DataFrame(cosine_sim, index=data['Judulfilm'], columns=data['Judulfilm'])
print('Shape:', cosine_sim_df.shape)
 
# Melihat similarity matrix pada setiap judul film
cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

def film_recommendations(nama_film, similarity_data=cosine_sim_df, items=data[['Judulfilm', 'Genrefilm']], k=5):
 
    index = similarity_data.loc[:,nama_film].to_numpy().argpartition(
        range(-1, -k, -1))
    
    # Mengambil data dengan similarity terbesar dari index yang ada
    closest = similarity_data.columns[index[-1:-(k+2):-1]]
    
    # Drop nama_film agar nama film yang dicari tidak muncul dalam daftar rekomendasi
    closest = closest.drop(nama_film, errors='ignore')
 
    return pd.DataFrame(closest).merge(items).head(k)

data[data.Judulfilm.eq('Toy Story')]

film_recommendations('Toy Story')